---
title: "analysis"
author: "Josef Klafka and Allyson Ettinger"
date: "1/22/2020"
output: html_document
---

```{r setup, include=FALSE}
require(tidyverse)
require(tidytext)
require(here)

knitr::opts_chunk$set(echo = TRUE)
```

```{r read results}
# clean_results <- read_csv(here("Results/clean-results.csv"), 
#                     col_names = c("Input", "Prediction", "Output", "Correct"))

noisy_results <- read_csv(here("Results/noisy-test.csv"), 
                    col_names = c("Input", "Prediction", "Output", "Correct", 
                                  "Noisetype", "Noiselocation")) %>%
  filter(str_detect(Correct, pattern = "\\d+")) %>%
  mutate(Correct = as.numeric(Correct))

# results %>% 
#   clean_results %>% 
#   bind_rows(noisy_results)
```

Training on 10000 iterations, testing on 1000. For all noisy and clean results, we achieve $21\%$ complete accuracy at the sentence level, and $67\%$ mean accuracy at the word level. On the clean results only, we get $40\%$ accuracy at the sentence level and $86.6\%$ accuracy at the word level. 

```{r plot proportion correct}
noisy_results %>% 
  ggplot(aes(x = Correct)) + 
    geom_histogram(binwidth = .05)

noisy_results %>% pull(Correct) %>% mean()
(noisy_results %>% filter(Correct == 1.0) %>% nrow()) / (noisy_results %>% nrow())

only_noise <- noisy_results %>% 
  filter(Input != Output) 
only_noise %>% pull(Correct) %>% mean()
(only_noise %>% filter(Correct == 1.0) %>% nrow()) / (only_noise %>% nrow())
```

```{r how did sdae do on the clean sentences}
clean_results <- noisy_results %>%
  filter(Input == Output)

clean_results %>% 
  ggplot(aes(x = Correct)) + 
    geom_histogram(binwidth = .05)

clean_results %>% pull(Correct) %>% mean()
(clean_results %>% filter(Correct == 1.0) %>% nrow()) / (clean_results %>% nrow())
```

```{r analyzing what went wrong}
## how many words in common between prediction and output
predictions <- noisy_results %>%
  mutate(id = 1:n()) %>%
  select(id, Prediction) %>%
  unnest_tokens(word, Prediction)
  
outputs <- noisy_results %>%
  mutate(id = 1:n()) %>%
  select(id, Output) %>%
  unnest_tokens(word, Output)

predictions %>%
  left_join(outputs, by = "id") %>% 
  mutate(Correct = ifelse(word.x == word.y, 1, 0)) %>%
  group_by(id) %>%
  mutate(word_id = 1:n()) %>%
  summarize(Percent = sum(Correct) / max(word_id)) %>%
  
```