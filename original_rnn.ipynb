{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, requests, spacy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the RNN and the text encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size = 10, \n",
    "             hidden_size = 10, \n",
    "             num_layers = 12, # twelve stacked RNNs\n",
    "             nonlinearity = \"relu\", \n",
    "             bias = True, # use biases when computing weights\n",
    "             dropout = 0.05) # 5% dropout chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our sample text: the Dunwich Horror from Project Gutenberg\n",
    "dunwich = requests.get(\"http://www.gutenberg.org/cache/epub/50133/pg50133.txt\").text.replace(\"\\r\\n\", ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split roughly by sentence\n",
    "dunwich_doc = nlp(dunwich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word dictionary\n",
    "word_to_index = {\"SOS\" : 0, \"EOS\" : 1}\n",
    "index_counter = 2\n",
    "for sentence in dunwich_doc.sents: \n",
    "    for word in sentence.split(' '):\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = index_counter\n",
    "            index_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as many words in vocab as we have, 10-dimensional embeddings\n",
    "embedder = nn.Embedding(len(word_to_index), 10)\n",
    "# embedder(torch.tensor(word_to_index[\"the\"], dtype=torch.long)) ##for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in dunwich_doc.sents:\n",
    "    split_sen = sentence.split(' ')\n",
    "    split_sen = [\"SOS\"] + split_sen + [\"EOS\"]\n",
    "    for word in split_sen: \n",
    "        word_tensor = torch.tensor(word_to_index[word], dtype=torch.long)\n",
    "        word_embedding = embedder(word_tensor).view(1, 1, -1)\n",
    "#         print(word_embedding)\n",
    "#         print(word_embedding.shape)\n",
    "        output, hidden = rnn(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0036,  0.3917,  0.0468,  0.3292, -0.0977, -0.4626,  0.0911,\n",
      "           0.0535, -0.2949, -0.1314, -0.1678, -0.0357,  0.1055, -0.0297,\n",
      "          -0.4444,  0.1476, -0.0519, -0.3298,  0.3994,  0.1278]]],\n",
      "       grad_fn=<StackBackward>)\n",
      "tensor([[[-0.0026, -0.1780, -0.3283, -0.4559, -0.4013, -0.7013,  0.5285,\n",
      "           0.1625, -0.5172,  0.3406, -0.2765, -0.0162,  0.4635,  0.2531,\n",
      "          -0.4851,  0.1977,  0.5198,  0.5070,  0.5302,  0.5003]],\n",
      "\n",
      "        [[-0.0036,  0.3917,  0.0468,  0.3292, -0.0977, -0.4626,  0.0911,\n",
      "           0.0535, -0.2949, -0.1314, -0.1678, -0.0357,  0.1055, -0.0297,\n",
      "          -0.4444,  0.1476, -0.0519, -0.3298,  0.3994,  0.1278]]],\n",
      "       grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "output, hn = rnn(input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EncoderRNN(nn.module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # define layers\n",
    "        self.embedding = nn.Embedding()\n",
    "        self.hidden = nn\n",
    "        \n",
    "    def forward(input_text):\n",
    "        output = self.embedding(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(encoder, text):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
